{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5962731,"sourceType":"datasetVersion","datasetId":3419493}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport os\nimport keras\nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom PIL import Image\nfrom keras.layers import Conv2D,Flatten,Dense,Dropout,BatchNormalization,MaxPooling2D\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2025-10-01T00:05:10.126783Z","iopub.execute_input":"2025-10-01T00:05:10.127465Z","iopub.status.idle":"2025-10-01T00:05:18.465528Z","shell.execute_reply.started":"2025-10-01T00:05:10.127425Z","shell.execute_reply":"2025-10-01T00:05:18.464703Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Import Dataset","metadata":{}},{"cell_type":"code","source":"import os\nimport random\n\ndef collect_image_paths(directory):\n    paths = []\n    for dirname, _, filenames in os.walk(directory):\n        for filename in filenames:\n            paths.append(os.path.join(dirname, filename))\n    return paths\n\n# Collect image paths\npath1 = collect_image_paths('/kaggle/input/imagesoasis/Data/Non Demented')\npath2 = collect_image_paths('/kaggle/input/imagesoasis/Data/Mild Dementia')\npath3 = collect_image_paths('/kaggle/input/imagesoasis/Data/Moderate Dementia')\npath4 = collect_image_paths('/kaggle/input/imagesoasis/Data/Very mild Dementia')\n\n# Set the size of the sample\nsize = 400  # You can change this value as needed\n\n# Set seed for reproducibility\nrandom.seed(42)\n\n# Sample random paths\nsample_path1 = random.sample(path1, min(size, len(path1)))\nsample_path2 = random.sample(path2, min(size, len(path2)))\nsample_path3 = random.sample(path3, min(size, len(path3)))\nsample_path4 = random.sample(path4, min(size, len(path4)))\n\n# Output the sample sizes\nprint(f'Sampled {len(sample_path1)} paths from Non Demented')\nprint(f'Sampled {len(sample_path2)} paths from Mild Dementia')\nprint(f'Sampled {len(sample_path3)} paths from Moderate Dementia')\nprint(f'Sampled {len(sample_path4)} paths from Very mild Dementia')\n","metadata":{"execution":{"iopub.status.busy":"2025-10-01T00:05:18.467664Z","iopub.execute_input":"2025-10-01T00:05:18.468655Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# One Hot Encoding","metadata":{}},{"cell_type":"code","source":"# Initialize the encoder\nencoder = OneHotEncoder()\n\n# Fit the encoder on your categorical data\nencoder.fit([[0], [1], [2], [3]])\n\n# 0 --> Non Demented\n# 1 --> Mild Dementia\n# 2 --> Moderate Dementia\n# 3 --> Very Mild Dementia","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data = []\nresult = []\nfor path in sample_path1:\n    img = Image.open(path)\n    img = img.resize((128,128))\n    img = np.array(img)\n    if(img.shape == (128,128,3)):\n        data.append(np.array(img))\n        result.append(encoder.transform([[0]]).toarray())\n        \nfor path in sample_path2:\n    img = Image.open(path)\n    img = img.resize((128,128))\n    img = np.array(img)\n    if(img.shape == (128,128,3)):\n        data.append(np.array(img))\n        result.append(encoder.transform([[1]]).toarray()) \n        \nfor path in sample_path3:\n    img = Image.open(path)\n    img = img.resize((128,128))\n    img = np.array(img)\n    if(img.shape == (128,128,3)):\n        data.append(np.array(img))\n        result.append(encoder.transform([[2]]).toarray())\n        \nfor path in sample_path4:\n    img = Image.open(path)\n    img = img.resize((128,128))\n    img = np.array(img)\n    if(img.shape == (128,128,3)):\n        data.append(np.array(img))\n        result.append(encoder.transform([[3]]).toarray())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data = np.array(data)\ndata.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"result = np.array(result)\nresult = result.reshape((1600,4))\nresult.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# splitting The Data","metadata":{}},{"cell_type":"code","source":"x_train,x_test,y_train,y_test = train_test_split(data,result,test_size=0.15,shuffle=True,random_state=42)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Creating Model: CNN","metadata":{}},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(32,kernel_size =(2,2),input_shape = (128,128,3),padding = 'Same'))\nmodel.add(Conv2D(32,kernel_size =(2,2),activation='relu',padding = 'Same'))\n\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64,kernel_size =(2,2),activation='relu',padding = 'Same'))\nmodel.add(Conv2D(64,kernel_size =(2,2),activation='relu',padding = 'Same'))\n\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2),strides = (2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\n          \nmodel.add(Dense(512,activation = 'relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(4,activation='softmax'))\n          \nmodel.compile(loss = 'categorical_crossentropy',optimizer = 'Adamax',metrics=['accuracy'])\n          \nprint(model.summary())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_train.shape  ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x_train.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = model.fit(x_train,y_train,epochs=10,batch_size=10,verbose=1,validation_data=(x_test,y_test))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.xlabel('Loss')\nplt.ylabel('Epoch')\nplt.legend(['Test','Validation'],loc='upper right')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Accuracy and Prediction","metadata":{}},{"cell_type":"code","source":"def names(number):\n    if number == 0:\n        return 'Non Demented'\n    elif number == 1:\n        return 'Mild Dementia'\n    elif number == 2:\n        return 'Moderate Dementia'\n    elif number == 3:\n        return 'Very Mild Dementia'\n    else:\n        return 'Error in Prediction'\n# 0 --> Non Demented\n# 1 --> Mild Dementia\n# 2 --> Moderate Dementia\n# 3 --> Very Mild Dementia    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from matplotlib.pyplot import imshow\nimg = Image.open(r'/kaggle/input/imagesoasis/Data/Moderate Dementia/OAS1_0308_MR1_mpr-1_101.jpg')\nx = np.array(img.resize((128,128)))\nx = x.reshape(1,128,128,3)\nres=model.predict_on_batch(x)\nclassification = np.where(res == np.amax(res))[1][0]\nimshow(img)\nprint(str(res[0][classification]*100)+ '% Confidence This Is '+ names(classification))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img = Image.open(r'/kaggle/input/imagesoasis/Data/Very mild Dementia/OAS1_0003_MR1_mpr-1_117.jpg')\nx = np.array(img.resize((128,128)))\nx = x.reshape(1,128,128,3)\nres=model.predict_on_batch(x)\nclassification = np.where(res == np.amax(res))[1][0]\nimshow(img)\nprint(str(res[0][classification]*100)+ '% Confidence This Is '+ names(classification))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img = Image.open(r'/kaggle/input/imagesoasis/Data/Mild Dementia/OAS1_0028_MR1_mpr-1_145.jpg')\nx = np.array(img.resize((128,128)))\nx = x.reshape(1,128,128,3)\nres=model.predict_on_batch(x)\nclassification = np.where(res == np.amax(res))[1][0]\nimshow(img)\nprint(str(res[0][classification]*100)+ '% Confidence This Is '+ names(classification))","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}