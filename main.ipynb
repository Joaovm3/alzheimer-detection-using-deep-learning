{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T02:40:42.357435Z",
     "iopub.status.busy": "2025-10-01T02:40:42.357118Z",
     "iopub.status.idle": "2025-10-01T02:40:50.880361Z",
     "shell.execute_reply": "2025-10-01T02:40:50.879457Z",
     "shell.execute_reply.started": "2025-10-01T02:40:42.357411Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import keras\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from PIL import Image\n",
    "from keras.layers import Conv2D,Flatten,Dense,Dropout,BatchNormalization,MaxPooling2D\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"ninadaithal/imagesoasis\")\n",
    "# ref_df = create_ref_df('/kaggle/input/imagesoasis/Data')\n",
    "print(\"Path to dataset files:\", path)\n",
    "# print(\"df shape:\", ref_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T02:40:50.883194Z",
     "iopub.status.busy": "2025-10-01T02:40:50.882256Z",
     "iopub.status.idle": "2025-10-01T02:43:07.861730Z",
     "shell.execute_reply": "2025-10-01T02:43:07.860784Z",
     "shell.execute_reply.started": "2025-10-01T02:40:50.883159Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "def collect_image_paths(directory):\n",
    "    paths = []\n",
    "    for dirname, _, filenames in os.walk(directory):\n",
    "        for filename in filenames:\n",
    "            paths.append(os.path.join(dirname, filename))\n",
    "    return paths\n",
    "\n",
    "path1 = collect_image_paths(os.path.join(path, 'Data/Non Demented'))\n",
    "path2 = collect_image_paths(os.path.join(path, 'Data/Mild Dementia'))\n",
    "path3 = collect_image_paths(os.path.join(path, 'Data/Moderate Dementia'))\n",
    "path4 = collect_image_paths(os.path.join(path, 'Data/Very mild Dementia'))\n",
    "\n",
    "# Set the size of the sample\n",
    "size = 400  # You can change this value as needed\n",
    "\n",
    "# Set seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Sample random paths\n",
    "sample_path1 = random.sample(path1, min(size, len(path1)))\n",
    "sample_path2 = random.sample(path2, min(size, len(path2)))\n",
    "sample_path3 = random.sample(path3, min(size, len(path3)))\n",
    "sample_path4 = random.sample(path4, min(size, len(path4)))\n",
    "\n",
    "# Output the sample sizes\n",
    "print(f'Sampled {len(sample_path1)} paths from Non Demented')\n",
    "print(f'Sampled {len(sample_path2)} paths from Mild Dementia')\n",
    "print(f'Sampled {len(sample_path3)} paths from Moderate Dementia')\n",
    "print(f'Sampled {len(sample_path4)} paths from Very mild Dementia')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "classes = ['Non Demented', 'Mild Dementia', 'Moderate Dementia', 'Very mild Dementia']\n",
    "for class_name in classes:\n",
    "    class_path = os.path.join(path, f\"Data/{class_name}\")\n",
    "    num_images = len([f for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))])\n",
    "    print(f\"Classe '{class_name}': {num_images} imagens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def show_images_from_class(class_name, num_images=5):\n",
    "    class_path = os.path.join(path, f\"Data/{class_name}\")\n",
    "    images = [os.path.join(class_path, f) for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))]\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i, img_path in enumerate(images[:num_images]):\n",
    "        img = Image.open(img_path)\n",
    "        plt.subplot(1, num_images, i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(class_name)\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "for class_name in classes:\n",
    "    show_images_from_class(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_distribution = []\n",
    "for class_name in classes:\n",
    "    class_path = os.path.join(path, f\"Data/{class_name}\")\n",
    "    num_images = len([f for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))])\n",
    "    data_distribution.append({\"Class\": class_name, \"Amount\": num_images})\n",
    "\n",
    "df_distribution = pd.DataFrame(data_distribution)\n",
    "\n",
    "df_distribution['Class'] = ['non', 'mild', 'moderate', 'very']\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.barplot(x=\"Class\", y=\"Amount\", data=df_distribution, palette=\"viridis\")\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{int(p.get_height())}', \n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                ha='center', va='baseline', fontsize=10, color='black', xytext=(0, 5), \n",
    "                textcoords='offset points')\n",
    "\n",
    "plt.title(\"Class Image Distribution\", fontsize=14)\n",
    "plt.xlabel(\"Tumor type\", fontsize=12)\n",
    "plt.ylabel(\"Count\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = []\n",
    "for class_name in classes:\n",
    "    class_path = os.path.join(path, f\"Data/{class_name}\")\n",
    "    images = [os.path.join(class_path, f) for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))]\n",
    "    for img_path in images:\n",
    "        with Image.open(img_path) as img:\n",
    "            dimensions.append(img.size)\n",
    "\n",
    "df_dimensions = pd.DataFrame(dimensions, columns=[\"Largura\", \"Altura\"])\n",
    "\n",
    "print(\"Image Sizes:\")\n",
    "print(df_dimensions.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Configurar o gerador de data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Selecionar uma imagem da classe 'Moderate Dementia'\n",
    "img_path = sample_path3[0]  # Escolha uma imagem da classe\n",
    "img = Image.open(img_path).resize((128, 128))\n",
    "img_array = np.array(img).reshape((1,) + img.size + (3,))  # Redimensionar para o formato esperado pelo datagen\n",
    "\n",
    "# Gerar imagens augmentadas\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Mostrar a imagem original\n",
    "plt.subplot(1, 6, 1)\n",
    "plt.imshow(img)\n",
    "plt.title(\"Original\")\n",
    "plt.axis('off')\n",
    "\n",
    "# Mostrar imagens augmentadas\n",
    "for i, batch in enumerate(datagen.flow(img_array, batch_size=1)):\n",
    "    augmented_img = batch[0].astype(np.uint8)  # Converter para formato visualizável\n",
    "    plt.subplot(1, 6, i + 2)\n",
    "    plt.imshow(augmented_img)\n",
    "    plt.title(f\"Augmented {i+1}\")\n",
    "    plt.axis('off')\n",
    "    if i == 4:  # Mostrar 5 imagens augmentadas\n",
    "        break\n",
    "\n",
    "plt.suptitle(\"Comparação: Original e Imagens Augmentadas - Moderate Dementia\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T02:43:07.862972Z",
     "iopub.status.busy": "2025-10-01T02:43:07.862722Z",
     "iopub.status.idle": "2025-10-01T02:43:07.875356Z",
     "shell.execute_reply": "2025-10-01T02:43:07.874664Z",
     "shell.execute_reply.started": "2025-10-01T02:43:07.862952Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize the encoder\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Fit the encoder on your categorical data\n",
    "encoder.fit([[0], [1], [2], [3]])\n",
    "\n",
    "# 0 --> Non Demented\n",
    "# 1 --> Mild Dementia\n",
    "# 2 --> Moderate Dementia\n",
    "# 3 --> Very Mild Dementia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T02:43:07.876708Z",
     "iopub.status.busy": "2025-10-01T02:43:07.876431Z",
     "iopub.status.idle": "2025-10-01T02:43:20.779320Z",
     "shell.execute_reply": "2025-10-01T02:43:20.778654Z",
     "shell.execute_reply.started": "2025-10-01T02:43:07.876687Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "result = []\n",
    "for path in sample_path1:\n",
    "    img = Image.open(path)\n",
    "    img = img.resize((128,128))\n",
    "    img = np.array(img)\n",
    "    if(img.shape == (128,128,3)):\n",
    "        data.append(np.array(img))\n",
    "        result.append(encoder.transform([[0]]).toarray())\n",
    "        \n",
    "for path in sample_path2:\n",
    "    img = Image.open(path)\n",
    "    img = img.resize((128,128))\n",
    "    img = np.array(img)\n",
    "    if(img.shape == (128,128,3)):\n",
    "        data.append(np.array(img))\n",
    "        result.append(encoder.transform([[1]]).toarray()) \n",
    "        \n",
    "for path in sample_path3:\n",
    "    img = Image.open(path)\n",
    "    img = img.resize((128,128))\n",
    "    img = np.array(img)\n",
    "    if(img.shape == (128,128,3)):\n",
    "        data.append(np.array(img))\n",
    "        result.append(encoder.transform([[2]]).toarray())\n",
    "        \n",
    "for path in sample_path4:\n",
    "    img = Image.open(path)\n",
    "    img = img.resize((128,128))\n",
    "    img = np.array(img)\n",
    "    if(img.shape == (128,128,3)):\n",
    "        data.append(np.array(img))\n",
    "        result.append(encoder.transform([[3]]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T02:43:20.781854Z",
     "iopub.status.busy": "2025-10-01T02:43:20.781559Z",
     "iopub.status.idle": "2025-10-01T02:43:20.813656Z",
     "shell.execute_reply": "2025-10-01T02:43:20.812804Z",
     "shell.execute_reply.started": "2025-10-01T02:43:20.781832Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T02:43:20.814912Z",
     "iopub.status.busy": "2025-10-01T02:43:20.814603Z",
     "iopub.status.idle": "2025-10-01T02:43:20.822049Z",
     "shell.execute_reply": "2025-10-01T02:43:20.821201Z",
     "shell.execute_reply.started": "2025-10-01T02:43:20.814890Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "result = np.array(result)\n",
    "result = result.reshape((1600,4))\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T02:43:20.823242Z",
     "iopub.status.busy": "2025-10-01T02:43:20.823025Z",
     "iopub.status.idle": "2025-10-01T02:43:20.851592Z",
     "shell.execute_reply": "2025-10-01T02:43:20.850698Z",
     "shell.execute_reply.started": "2025-10-01T02:43:20.823223Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(data,result,test_size=0.15,shuffle=True,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Model: CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T02:43:20.853003Z",
     "iopub.status.busy": "2025-10-01T02:43:20.852722Z",
     "iopub.status.idle": "2025-10-01T02:43:22.077436Z",
     "shell.execute_reply": "2025-10-01T02:43:22.076510Z",
     "shell.execute_reply.started": "2025-10-01T02:43:20.852982Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.models import load_model\n",
    "import json\n",
    "\n",
    "model_path = \"./alzheimer_model.keras\"\n",
    "history_path = \"./training_history.json\"\n",
    "enable_load_model = False # Trocar pra True depois que finalizar os testes\n",
    "\n",
    "if os.path.exists(model_path) and enable_load_model:\n",
    "    print(\"Carregando modelo salvo...\")\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    if os.path.exists(history_path):\n",
    "      with open(history_path, \"r\") as f:\n",
    "        history = json.load(f)\n",
    "      print(\"Histórico de treinamento carregado com sucesso!\")\n",
    "    else:\n",
    "      history = None\n",
    "      print(\"Histórico de treinamento não encontrado.\")\n",
    "else:\n",
    "  print(\"Nenhum modelo salvo encontrado. Criando um novo modelo...\")\n",
    "  model = Sequential()\n",
    "\n",
    "  model.add(Conv2D(32,kernel_size =(2,2),input_shape = (128,128,3),padding = 'Same'))\n",
    "  model.add(Conv2D(32,kernel_size =(2,2),activation='relu',padding = 'Same'))\n",
    "\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "  model.add(Dropout(0.25))\n",
    "\n",
    "  model.add(Conv2D(64,kernel_size =(2,2),activation='relu',padding = 'Same'))\n",
    "  model.add(Conv2D(64,kernel_size =(2,2),activation='relu',padding = 'Same'))\n",
    "\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(MaxPooling2D(pool_size=(2,2),strides = (2,2)))\n",
    "  model.add(Dropout(0.25))\n",
    "\n",
    "  model.add(Flatten())\n",
    "              \n",
    "  model.add(Dense(512,activation = 'relu'))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(4,activation='softmax'))\n",
    "              \n",
    "  model.compile(loss = 'categorical_crossentropy',optimizer = 'Adamax',metrics=['accuracy'])\n",
    "\n",
    "  # train the model\n",
    "  history = model.fit(x_train,y_train,epochs=10,batch_size=10,verbose=1,validation_data=(x_test,y_test))\n",
    "  model.save(model_path)\n",
    "  # Salvar o histórico de treinamento\n",
    "  with open(history_path, \"w\") as f:\n",
    "    json.dump(history.history, f)\n",
    "\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T02:43:22.079382Z",
     "iopub.status.busy": "2025-10-01T02:43:22.078789Z",
     "iopub.status.idle": "2025-10-01T02:43:22.085143Z",
     "shell.execute_reply": "2025-10-01T02:43:22.084256Z",
     "shell.execute_reply.started": "2025-10-01T02:43:22.079350Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_train.shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T02:43:22.086892Z",
     "iopub.status.busy": "2025-10-01T02:43:22.086280Z",
     "iopub.status.idle": "2025-10-01T02:43:22.097544Z",
     "shell.execute_reply": "2025-10-01T02:43:22.096713Z",
     "shell.execute_reply.started": "2025-10-01T02:43:22.086868Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T02:43:46.252127Z",
     "iopub.status.busy": "2025-10-01T02:43:46.251827Z",
     "iopub.status.idle": "2025-10-01T02:43:46.495836Z",
     "shell.execute_reply": "2025-10-01T02:43:46.494916Z",
     "shell.execute_reply.started": "2025-10-01T02:43:46.252104Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Loss')\n",
    "plt.ylabel('Epoch')\n",
    "plt.legend(['Test','Validation'],loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T03:14:22.198891Z",
     "iopub.status.busy": "2025-10-01T03:14:22.198540Z",
     "iopub.status.idle": "2025-10-01T03:14:22.205332Z",
     "shell.execute_reply": "2025-10-01T03:14:22.204445Z",
     "shell.execute_reply.started": "2025-10-01T03:14:22.198863Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "def names(number):\n",
    "    if number == 0:\n",
    "        return 'Sem demência'\n",
    "    elif number == 1:\n",
    "        return 'Demência Leve'\n",
    "    elif number == 2:\n",
    "        return 'Demência Moderada'\n",
    "    elif number == 3:\n",
    "        return 'Demência Muito Leve'\n",
    "    else:\n",
    "        return 'Erro na Predição'\n",
    "\n",
    "def print_prediction(img_url): \n",
    "    img = Image.open(img_url).convert(\"RGB\")\n",
    "    x = np.array(img.resize((128,128)))\n",
    "    x = x.reshape(1,128,128,3)\n",
    "    res=model.predict_on_batch(x)\n",
    "    classification = np.where(res == np.amax(res))[1][0]\n",
    "    imshow(img)\n",
    "    print(str(res[0][classification]*100)+ '% de confiança de ser '+ names(classification))\n",
    "        \n",
    "# 0 --> Non Demented\n",
    "# 1 --> Mild Dementia\n",
    "# 2 --> Moderate Dementia\n",
    "# 3 --> Very Mild Dementia    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T03:14:24.220863Z",
     "iopub.status.busy": "2025-10-01T03:14:24.220524Z",
     "iopub.status.idle": "2025-10-01T03:14:24.481474Z",
     "shell.execute_reply": "2025-10-01T03:14:24.480673Z",
     "shell.execute_reply.started": "2025-10-01T03:14:24.220835Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "path_test = os.path.join(path, r'Data/Moderate Dementia/OAS1_0308_MR1_mpr-1_101.jpg')\n",
    "print_prediction(path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T03:14:27.644514Z",
     "iopub.status.busy": "2025-10-01T03:14:27.643731Z",
     "iopub.status.idle": "2025-10-01T03:14:27.860305Z",
     "shell.execute_reply": "2025-10-01T03:14:27.859391Z",
     "shell.execute_reply.started": "2025-10-01T03:14:27.644485Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print_prediction(r'/kaggle/input/test-images/test.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T03:11:12.420655Z",
     "iopub.status.busy": "2025-10-01T03:11:12.420355Z",
     "iopub.status.idle": "2025-10-01T03:11:12.860692Z",
     "shell.execute_reply": "2025-10-01T03:11:12.859926Z",
     "shell.execute_reply.started": "2025-10-01T03:11:12.420633Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print_prediction(r'/kaggle/input/test-images/demencia moderada.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T03:00:09.823869Z",
     "iopub.status.busy": "2025-10-01T03:00:09.823163Z",
     "iopub.status.idle": "2025-10-01T03:00:10.082097Z",
     "shell.execute_reply": "2025-10-01T03:00:10.081262Z",
     "shell.execute_reply.started": "2025-10-01T03:00:09.823839Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "path_test = os.path.join(path, r'Data/Very mild Dementia/OAS1_0003_MR1_mpr-1_117.jpg')\n",
    "print_prediction(path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T02:45:21.206951Z",
     "iopub.status.busy": "2025-10-01T02:45:21.206605Z",
     "iopub.status.idle": "2025-10-01T02:45:21.399772Z",
     "shell.execute_reply": "2025-10-01T02:45:21.399023Z",
     "shell.execute_reply.started": "2025-10-01T02:45:21.206924Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print_prediction(os.path.join(path, 'Data/Mild Dementia/OAS1_0028_MR1_mpr-1_145.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T02:47:48.167798Z",
     "iopub.status.busy": "2025-10-01T02:47:48.166900Z",
     "iopub.status.idle": "2025-10-01T02:47:48.623703Z",
     "shell.execute_reply": "2025-10-01T02:47:48.622953Z",
     "shell.execute_reply.started": "2025-10-01T02:47:48.167739Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=1)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T02:53:40.576518Z",
     "iopub.status.busy": "2025-10-01T02:53:40.576214Z",
     "iopub.status.idle": "2025-10-01T02:53:41.093977Z",
     "shell.execute_reply": "2025-10-01T02:53:41.092979Z",
     "shell.execute_reply.started": "2025-10-01T02:53:40.576495Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy and loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['accuracy'], label='Train Acc')\n",
    "plt.plot(history['val_accuracy'], label='Val Acc')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Val Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T02:53:52.100522Z",
     "iopub.status.busy": "2025-10-01T02:53:52.100188Z",
     "iopub.status.idle": "2025-10-01T02:53:52.423976Z",
     "shell.execute_reply": "2025-10-01T02:53:52.422978Z",
     "shell.execute_reply.started": "2025-10-01T02:53:52.100495Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "y_pred_probs = model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_true, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "import seaborn as sns\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Non\", \"Mild\", \"Mod\", \"Very Mild\"], yticklabels=[\"Non\", \"Mild\", \"Mod\", \"Very Mild\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3419493,
     "sourceId": 5962731,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8381324,
     "sourceId": 13222874,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30559,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
